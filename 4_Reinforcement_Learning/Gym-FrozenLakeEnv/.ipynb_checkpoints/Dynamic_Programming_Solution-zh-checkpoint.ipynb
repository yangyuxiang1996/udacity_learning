{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迷你项目：动态规划\n",
    "\n",
    "在此 notebook 中，你将自己编写很多经典动态规划算法的实现。\n",
    "\n",
    "虽然我们提供了一些起始代码，但是你可以删掉这些提示并从头编写代码。\n",
    "\n",
    "### 第 0 部分：探索 FrozenLakeEnv\n",
    "\n",
    "请使用以下代码单元格创建 [FrozenLake](https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py) 环境的实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frozenlake import FrozenLakeEnv\n",
    "\n",
    "env = FrozenLakeEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "智能体将会在 $4 \\times 4$ 网格世界中移动，状态编号如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "智能体可以执行 4 个潜在动作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，$\\mathcal{S}^+ = \\{0, 1, \\ldots, 15\\}$ 以及 $\\mathcal{A} = \\{0, 1, 2, 3\\}$。请通过运行以下代码单元格验证这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(16)\n",
      "Discrete(4)\n",
      "16\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# print the state space and action space\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "\n",
    "# print the total number of states and actions\n",
    "print(env.nS)\n",
    "print(env.nA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "动态规划假设智能体完全了解 MDP。我们已经修改了 `frozenlake.py` 文件以使智能体能够访问一步动态特性。  \n",
    "\n",
    "请执行以下代码单元格以返回特定状态和动作对应的一步动态特性。具体而言，当智能体在网格世界中以状态 1 向左移动时，`env.P[1][0]` 会返回每个潜在奖励的概率和下一个状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3333333333333333, 1, 0.0, False),\n",
       " (0.3333333333333333, 0, 0.0, False),\n",
       " (0.3333333333333333, 5, 0.0, True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个条目的格式如下所示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prob, next_state, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中：\n",
    "- `prob` 详细说明了相应的  (`next_state`, `reward`) 对的条件概率，以及\n",
    "- 如果 `next_state` 是终止状态，则 `done` 是 `True` ，否则是 `False`。\n",
    "\n",
    "因此，我们可以按照以下方式解析 `env.P[1][0]`：\n",
    "$$\n",
    "\\mathbb{P}(S_{t+1}=s',R_{t+1}=r|S_t=1,A_t=0) = \\begin{cases}\n",
    "               \\frac{1}{3} \\text{ if } s'=1, r=0\\\\\n",
    "               \\frac{1}{3} \\text{ if } s'=0, r=0\\\\\n",
    "               \\frac{1}{3} \\text{ if } s'=5, r=0\\\\\n",
    "               0 \\text{ else}\n",
    "            \\end{cases}\n",
    "$$\n",
    "\n",
    "你可以随意更改上述代码单元格，以探索在其他（状态、动作）对下环境的行为是怎样的。\n",
    "\n",
    "### 第 1 部分：迭代策略评估\n",
    "\n",
    "在此部分，你将自己编写迭代策略评估的实现。\n",
    "\n",
    "你的算法应该有四个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "- `theta`：这是一个非常小的正数，用于判断估算值是否足够地收敛于真值函数 (默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `V`：这是一个一维numpy数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 在输入策略下的估算值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def policy_evaluation(env, policy, gamma=1, theta=1e-8):\n",
    "    V = np.zeros(env.nS)\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in range(env.nS):\n",
    "            Vs = 0\n",
    "            for a, action_prob in enumerate(policy[s]):\n",
    "                for prob, next_state, reward, done in env.P[s][a]:\n",
    "                    Vs += action_prob * prob * (reward + gamma * V[next_state])\n",
    "            delta = max(delta, np.abs(V[s]-Vs))\n",
    "            V[s] = Vs\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将评估等概率随机策略  $\\pi$，其中对于所有 $s\\in\\mathcal{S}$ 和 $a\\in\\mathcal{A}(s)$ ，$\\pi(a|s) = \\frac{1}{|\\mathcal{A}(s)|}$。  \n",
    "\n",
    "请使用以下代码单元格在变量 `random_policy`中指定该策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = np.ones([env.nS, env.nA]) / env.nA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以评估等概率随机策略并可视化输出结果。状态值函数已调整形状，以匹配网格世界的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_utils import plot_values\n",
    "%matplotlib inline\n",
    "\n",
    "# evaluate the policy \n",
    "V = policy_evaluation(env, random_policy)\n",
    "\n",
    "plot_values(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_13_0.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保你的 `policy_evaluation` 函数满足上文列出的要求（具有四个输入、一个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import check_test\n",
    "\n",
    "check_test.run_check('policy_evaluation_check', policy_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 2 部分：通过 $v_\\pi$ 获取 $q_\\pi$\n",
    "\n",
    "在此部分，你将编写一个函数，该函数的输入是状态值函数估值以及一些状态 $s\\in\\mathcal{S}$。它会返回输入状态 $s\\in\\mathcal{S}$ 对应的**动作值函数中的行**。即你的函数应同时接受输入 $v_\\pi$ 和 $s$，并针对所有 $a\\in\\mathcal{A}(s)$ 返回 $q_\\pi(s,a)$。\n",
    "\n",
    "你的算法应该有四个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "- `s`：这是环境中的状态对应的整数。它应该是在 `0` 到 `(env.nS)-1`（含）之间的值。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `q`：这是一个一维 numpy 数组，其中 `q.shape[0]` 等于动作数量 (`env.nA`)。`q[a]` 包含状态 `s` 和动作 `a` 的（估算）值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_from_v(env, V, s, gamma=1):\n",
    "    q = np.zeros(env.nA)\n",
    "    for a in range(env.nA):\n",
    "        for prob, next_state, reward, done in env.P[s][a]:\n",
    "            q[a] += prob * (reward + gamma * V[next_state])\n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请运行以下代码单元格以输出上述状态值函数对应的动作值函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros([env.nS, env.nA])\n",
    "for s in range(env.nS):\n",
    "    Q[s] = q_from_v(env, V, s)\n",
    "print(\"Action-Value Function:\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Action-Value Function:\n",
    "[[ 0.0147094   0.01393978  0.01393978  0.01317015]\n",
    " [ 0.00852356  0.01163091  0.0108613   0.01550788]\n",
    " [ 0.02444514  0.02095298  0.02406033  0.01435346]\n",
    " [ 0.01047649  0.01047649  0.00698432  0.01396865]\n",
    " [ 0.02166487  0.01701828  0.01624865  0.01006281]\n",
    " [ 0.          0.          0.          0.        ]\n",
    " [ 0.05433538  0.04735105  0.05433538  0.00698432]\n",
    " [ 0.          0.          0.          0.        ]\n",
    " [ 0.01701828  0.04099204  0.03480619  0.04640826]\n",
    " [ 0.07020885  0.11755991  0.10595784  0.05895312]\n",
    " [ 0.18940421  0.17582037  0.16001424  0.04297382]\n",
    " [ 0.          0.          0.          0.        ]\n",
    " [ 0.          0.          0.          0.        ]\n",
    " [ 0.08799677  0.20503718  0.23442716  0.17582037]\n",
    " [ 0.25238823  0.53837051  0.52711478  0.43929118]\n",
    " [ 0.          0.          0.          0.        ]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `q_from_v` 函数满足上文列出的要求（具有四个输入、一个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_test.run_check('q_from_v_check', q_from_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 3 部分：策略改进\n",
    "\n",
    "在此部分，你将自己编写策略改进实现。 \n",
    "\n",
    "你的算法应该有三个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "\n",
    "请完成以下代码单元格中的函数。建议你使用你在上文实现的 `q_from_v` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(env, V, gamma=1):\n",
    "    policy = np.zeros([env.nS, env.nA]) / env.nA\n",
    "    for s in range(env.nS):\n",
    "        q = q_from_v(env, V, s, gamma)\n",
    "        \n",
    "        # OPTION 1: construct a deterministic policy \n",
    "        # policy[s][np.argmax(q)] = 1\n",
    "        \n",
    "        # OPTION 2: construct a stochastic policy that puts equal probability on maximizing actions\n",
    "        best_a = np.argwhere(q==np.max(q)).flatten()\n",
    "        policy[s] = np.sum([np.eye(env.nA)[i] for i in best_a], axis=0)/len(best_a)\n",
    "        \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `policy_improvement` 函数满足上文列出的要求（具有三个输入、一个输出，并且没有更改输入参数的默认值）。\n",
    "\n",
    "在继续转到该 notebook 的下个部分之前，强烈建议你参阅 **Dynamic_Programming_Solution.ipynb** 中的解决方案。该函数有很多正确的实现方式！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_test.run_check('policy_improvement_check', policy_improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 4 部分：策略迭代\n",
    "\n",
    "在此部分，你将自己编写策略迭代的实现。该算法会返回最优策略，以及相应的状态值函数。\n",
    "\n",
    "你的算法应该有三个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "- `theta`：这是一个非常小的正数，用于判断策略评估步骤是否足够地收敛于真值函数 (默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "\n",
    "请完成以下代码单元格中的函数。强烈建议你使用你在上文实现的 `policy_evaluation` 和 `policy_improvement` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def policy_iteration(env, gamma=1, theta=1e-8):\n",
    "    policy = np.ones([env.nS, env.nA]) / env.nA\n",
    "    while True:\n",
    "        V = policy_evaluation(env, policy, gamma, theta)\n",
    "        new_policy = policy_improvement(env, V)\n",
    "        \n",
    "        # OPTION 1: stop if the policy is unchanged after an improvement step\n",
    "        if (new_policy == policy).all():\n",
    "            break;\n",
    "        \n",
    "        # OPTION 2: stop if the value function estimates for successive policies has converged\n",
    "        # if np.max(abs(policy_evaluation(env, policy) - policy_evaluation(env, new_policy))) < theta*1e2:\n",
    "        #    break;\n",
    "        \n",
    "        policy = copy.copy(new_policy)\n",
    "    return policy, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以解决该 MDP 并可视化输出结果。最优状态值函数已调整形状，以匹配网格世界的形状。\n",
    "\n",
    "**将该最优状态值函数与此 notebook 第 1 部分的状态值函数进行比较**。_最优状态值函数一直都大于或等于等概率随机策略的状态值函数吗？_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the optimal policy and optimal state-value function\n",
    "policy_pi, V_pi = policy_iteration(env)\n",
    "\n",
    "# print the optimal policy\n",
    "print(\"\\nOptimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\")\n",
    "print(policy_pi,\"\\n\")\n",
    "\n",
    "plot_values(V_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\n",
    "[[ 1.    0.    0.    0.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.5   0.    0.5   0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    1.    0.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_29_1.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！  \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `policy_iteratio` 函数满足上文列出的要求（具有三个输入、两个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_test.run_check('policy_iteration_check', policy_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 5 部分：截断策略迭代\n",
    "\n",
    "在此部分，你将自己编写截断策略迭代的实现。  \n",
    "\n",
    "首先，你将实现截断策略评估。你的算法应该有五个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "- `max_it`：这是一个正整数，对应的是经历状态空间的次数（默认值为：`1`）。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_policy_evaluation(env, policy, V, max_it=1, gamma=1):\n",
    "    num_it=0\n",
    "    while num_it < max_it:\n",
    "        for s in range(env.nS):\n",
    "            v = 0\n",
    "            q = q_from_v(env, V, s, gamma)\n",
    "            for a, action_prob in enumerate(policy[s]):\n",
    "                v += action_prob * q[a]\n",
    "            V[s] = v\n",
    "        num_it += 1\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，你将实现截断策略迭代。你的算法应该接受五个**输入**参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `max_it`：这是一个正整数，对应的是经历状态空间的次数（默认值为：`1`）。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。\n",
    "- `theta`：这是一个非常小的正整数，用作停止条件（默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。\n",
    "\n",
    "请完成以下代码单元格中的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_policy_iteration(env, max_it=1, gamma=1, theta=1e-8):\n",
    "    V = np.zeros(env.nS)\n",
    "    policy = np.zeros([env.nS, env.nA]) / env.nA\n",
    "    while True:\n",
    "        policy = policy_improvement(env, V)\n",
    "        old_V = copy.copy(V)\n",
    "        V = truncated_policy_evaluation(env, policy, V, max_it, gamma)\n",
    "        if max(abs(V-old_V)) < theta:\n",
    "            break;\n",
    "    return policy, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以解决该 MDP 并可视化输出结果。状态值函数已调整形状，以匹配网格世界的形状。\n",
    "\n",
    "请实验不同的 `max_it` 参数值。始终都能获得最优状态值函数吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_tpi, V_tpi = truncated_policy_iteration(env, max_it=2)\n",
    "\n",
    "# print the optimal policy\n",
    "print(\"\\nOptimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\")\n",
    "print(policy_tpi,\"\\n\")\n",
    "\n",
    "# plot the optimal state-value function\n",
    "plot_values(V_tpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\n",
    "[[ 1.    0.    0.    0.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.5   0.    0.5   0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    1.    0.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_37_1.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！ \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `truncated_policy_iteration` 函数满足上文列出的要求（具有四个输入、两个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_test.run_check('truncated_policy_iteration_check', truncated_policy_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**\n",
    "\n",
    "\n",
    "### 第 6 部分：值迭代\n",
    "\n",
    "在此部分，你将自己编写值迭代的实现。\n",
    "\n",
    "你的算法应该接受三个输入参数：\n",
    "- `env`：这是 OpenAI Gym 环境的实例，其中 `env.P` 会返回一步动态特性。\n",
    "- `gamma`：这是折扣率。它必须是在 0 到 1（含）之间的值，默认值为：`1`。 \n",
    "- `theta`：这是一个非常小的正整数，用作停止条件（默认值为：`1e-8`）。\n",
    "\n",
    "该算法会返回以下**输出结果**：\n",
    "- `policy`：这是一个二维 numpy 数组，其中 `policy.shape[0]` 等于状态数量 (`env.nS`) ， `policy.shape[1]` 等于动作数量 (`env.nA`) 。`policy[s][a]`  返回智能体在状态 `s` 时根据该策略选择动作 `a` 的概率。\n",
    "- `V`：这是一个一维 numpy 数组，其中 `V.shape[0]` 等于状态数量 (`env.nS`)。`V[s]` 包含状态 `s` 的估值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, gamma=1, theta=1e-8):\n",
    "    V = np.zeros(env.nS)\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in range(env.nS):\n",
    "            v = V[s]\n",
    "            V[s] = max(q_from_v(env, V, s, gamma))\n",
    "            delta = max(delta,abs(V[s]-v))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    policy = policy_improvement(env, V, gamma)\n",
    "    return policy, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下个代码单元格以解决该 MDP 并可视化输出结果。状态值函数已调整形状，以匹配网格世界的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_vi, V_vi = value_iteration(env)\n",
    "\n",
    "# print the optimal policy\n",
    "print(\"\\nOptimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\")\n",
    "print(policy_vi,\"\\n\")\n",
    "\n",
    "# plot the optimal state-value function\n",
    "plot_values(V_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimal Policy (LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3):\n",
    "[[ 1.    0.    0.    0.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.5   0.    0.5   0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    0.    1.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 1.    0.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.25  0.25  0.25  0.25]\n",
    " [ 0.    0.    1.    0.  ]\n",
    " [ 0.    1.    0.    0.  ]\n",
    " [ 0.25  0.25  0.25  0.25]] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](output_43_1.png)\n",
    "\n",
    "\n",
    "运行以下代码单元格以测试你的函数。如果代码单元格返回 **PASSED**，则表明你正确地实现了该函数！ \n",
    "\n",
    "**注意：**为了确保结果准确，确保 `truncated_policy_iteration` 函数满足上文列出的要求（具有三个输入、两个输出，并且没有更改输入参数的默认值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_test.run_check('value_iteration_check', value_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: green;\">PASSED</span>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RL]",
   "language": "python",
   "name": "conda-env-RL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
